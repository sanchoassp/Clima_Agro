{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354bc1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy                 as np\n",
    "import pandas                as pd\n",
    "import glob                  as g\n",
    "from   datetime              import date\n",
    "\n",
    "from pyspark.sql             import SparkSession\n",
    "from pyspark.sql.types       import StringType\n",
    "from pyspark.sql.types       import TimestampType\n",
    "from pyspark.sql             import SQLContext\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions   import *\n",
    "from pyspark.sql             import Window\n",
    "from pyspark.sql.types       import *\n",
    "\n",
    "spark = (\n",
    "    SparkSession\n",
    "        .builder.master('local[*]')\n",
    "        .appName('Churn')\n",
    "        .config('spark.driver.memory','2g') \n",
    "        .config('spark.executor.memory','2g')\n",
    "        .config(\"spark.sql.legacy.timeParserPolicy\", \"LEGACY\")\n",
    "        .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n",
    "        .config('spark.ui.showConsoleProgress', True)\n",
    "        .config(\"viewsEnabled\", \"true\")\n",
    "        .config(\"spark.sql.debug.maxToStringFields\", 1000)\n",
    "        .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa95eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (spark.read.format(\"csv\") \n",
    "      .option(\"header\", \"True\") \n",
    "      .load('../Agro/raw_data/*.csv') \n",
    "      .withColumn(\"filename\", input_file_name())\n",
    "    )\n",
    "\n",
    "df = df.select(\n",
    "                'Date', 'RegionID', 'dewpoint_temperature_2m',\n",
    "                'max_temperature_2m', 'min_temperature_2m','temperature_2m',\n",
    "                'humidity',  'surface_pressure', 'total_precipitation',\n",
    "                'u_component_of_wind_10m', 'v_component_of_wind_10m', \n",
    "                )\n",
    "\n",
    "df = df.withColumnRenamed(\"RegionID\", \"CD_MUN\")\n",
    "\n",
    "df = df.withColumn('temperature_2m',df['temperature_2m'].cast(FloatType()))\n",
    "df = df.withColumn('max_temperature_2m',df['max_temperature_2m'].cast(FloatType()))\n",
    "df = df.withColumn('min_temperature_2m',df['min_temperature_2m'].cast(FloatType()))\n",
    "df = df.withColumn('humidity',df['humidity'].cast(FloatType()))\n",
    "df = df.withColumn('surface_pressure',df['surface_pressure'].cast(FloatType()))\n",
    "df = df.withColumn('total_precipitation',df['total_precipitation'].cast(FloatType()))\n",
    "df = df.withColumn('u_component_of_wind_10m',df['u_component_of_wind_10m'].cast(FloatType()))\n",
    "df = df.withColumn('v_component_of_wind_10m',df['v_component_of_wind_10m'].cast(FloatType()))\n",
    "\n",
    "\n",
    "\n",
    "d_para = (spark.read.format(\"csv\") \n",
    "      .option(\"header\", \"True\") \n",
    "      .load('../Agro/raw_data/de_para_IBGE.csv') \n",
    "    )\n",
    "\n",
    "d_para = d_para.withColumn('CD_MUN',d_para['CD_MUN'].cast(StringType()))\n",
    "\n",
    "\n",
    "df = (df.join(d_para, (df[\"CD_MUN\"] == d_para[\"CD_MUN\"]), how=\"inner\"))\n",
    "\n",
    "df = (df.groupby('SIGLA_UF','Date')\n",
    "               .agg(F.mean(\"temperature_2m\").alias(\"temperature_2m\"),\n",
    "                    F.mean(\"max_temperature_2m\").alias(\"max_temperature_2m\"),\n",
    "                    F.mean(\"min_temperature_2m\").alias(\"min_temperature_2m\"),\n",
    "                    F.mean(\"humidity\").alias(\"humidity\"),\n",
    "                    F.mean(\"surface_pressure\").alias(\"surface_pressure\"),\n",
    "                    F.mean(\"total_precipitation\").alias(\"total_precipitation\"),\n",
    "                    F.mean(\"u_component_of_wind_10m\").alias(\"u_component_of_wind_10m\"),\n",
    "                    F.mean(\"v_component_of_wind_10m\").alias(\"v_component_of_wind_10m\")\n",
    "                   )\n",
    "    )\n",
    "\n",
    "df = df.withColumn('temperature_2m', col('temperature_2m') - lit(273.15))\n",
    "df = df.withColumn('max_temperature_2m', col('max_temperature_2m') - lit(273.15))\n",
    "df = df.withColumn('min_temperature_2m', col('min_temperature_2m') - lit(273.15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b8b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    df.write.format(\"parquet\")\n",
    "    .mode(\"overwrite\")\n",
    "    .save(\"../Agro/raw_data/clima_Agro.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978ee67b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
